import os
import pandas as pd
import psycopg2
from sqlalchemy import create_engine

# Path to the directory containing the Excel files
excel_files_directory = r'C:\NFL Betting Model\DataSet'

# Check if the directory exists
if not os.path.exists(excel_files_directory):
    print(f"Directory {excel_files_directory} does not exist.")
    exit()

# Step 1: Connect to PostgreSQL
conn = psycopg2.connect(
    dbname="NFL_Betting_Model",   # Your PostgreSQL database
    user="postgres",              # Your PostgreSQL user
    password="Football1!",        # Your PostgreSQL password
    host="localhost",             # Hostname (localhost if running locally)
    port="5432"                   # Default PostgreSQL port
)
cursor = conn.cursor()

# Function to detect PostgreSQL data types from pandas data types
def get_postgres_type(dtype):
    if pd.api.types.is_integer_dtype(dtype):
        return "INTEGER"
    elif pd.api.types.is_float_dtype(dtype):
        return "FLOAT"
    elif pd.api.types.is_bool_dtype(dtype):
        return "BOOLEAN"
    else:
        return "TEXT"

# Step 2: Loop through all Excel files in the directory
for filename in os.listdir(excel_files_directory):
    if filename.endswith(".xlsx"):  # Only process .xlsx files
        file_path = os.path.join(excel_files_directory, filename)
        print(f"Processing file: {file_path}")
        
        # Step 3: Read the Excel file using pandas
        df = pd.read_excel(file_path)
        print(f"Loaded {len(df)} rows from {filename}")
        
        # Step 4: Dynamically create a table based on the Excel file name (if needed)
        table_name = os.path.splitext(filename)[0]  # Use the filename (without .xlsx) as table name
        columns = ', '.join(f'{col} {get_postgres_type(df[col].dtype)}' for col in df.columns)  # Dynamically detect column types

        create_table_query = f'CREATE TABLE IF NOT EXISTS {table_name} ({columns});'
        print(f"Creating table: {table_name} with columns: {columns}")
        cursor.execute(create_table_query)
        conn.commit()

        # Step 5: Insert data from Excel into the PostgreSQL table
        for i, row in df.iterrows():
            values = tuple(row)
            placeholders = ', '.join(['%s'] * len(row))
            insert_query = f'INSERT INTO {table_name} ({", ".join(df.columns)}) VALUES ({placeholders})'
            try:
                cursor.execute(insert_query, values)
            except Exception as e:
                print(f"Error inserting row into {table_name}: {e}")
                conn.rollback()  # Rollback in case of error to avoid partial inserts
            else:
                conn.commit()

        print(f"Uploaded data from {filename} to table '{table_name}'.")

# Step 6: Close the connection
cursor.close()
conn.close()

print("All Excel files processed and uploaded successfully!")
